{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.tuner import Tuner\n",
    "from pytorch_lightning.callbacks import ModelSummary, EarlyStopping\n",
    "\n",
    "from early_exit_resnet import EarlyExitResNet50\n",
    "from dataset import Flame2DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_module = Flame2DataModule(image_dir=\"../Flame2/254_RGB\", batch_size=1,transform=transform)\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-07-10 22:52:03.460251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 22:52:04.758112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "Batch size 16 failed, trying batch size 12\n",
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 12 succeeded, trying batch size 14\n",
      "Batch size 14 failed, trying batch size 13\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Finished batch size finder, will continue with full run using batch size 13\n",
      "Restoring states from the checkpoint path at /home/jovyan/early-exit/.scale_batch_size_bd550d10-cdc0-4765-b73f-dc37d2e89ae8.ckpt\n",
      "Restored all states from the checkpoint at /home/jovyan/early-exit/.scale_batch_size_bd550d10-cdc0-4765-b73f-dc37d2e89ae8.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params | Mode  | In sizes           | Out sizes                   \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0 | head1         | HeadNetworkPart1   | 234 K  | train | [1, 3, 254, 254]   | [[1, 256, 254, 254], [1, 3]]\n",
      "1 | head2         | HeadNetworkPart2   | 1.3 M  | train | [1, 256, 254, 254] | [[1, 512, 127, 127], [1, 3]]\n",
      "2 | head3         | HeadNetworkPart3   | 7.2 M  | train | [1, 512, 127, 127] | [[1, 1024, 64, 64], [1, 3]] \n",
      "3 | tail          | TailNetwork        | 15.0 M | train | [1, 1024, 64, 64]  | [1, 3]                      \n",
      "4 | accuracy1     | MulticlassAccuracy | 0      | train | ?                  | ?                           \n",
      "5 | accuracy2     | MulticlassAccuracy | 0      | train | ?                  | ?                           \n",
      "6 | accuracy3     | MulticlassAccuracy | 0      | train | ?                  | ?                           \n",
      "7 | accuracyfinal | MulticlassAccuracy | 0      | train | ?                  | ?                           \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.488    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d81a2c4369457991fc516da8c0c7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=11` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08cf036991e49e3a7a5050b26e25a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_acc_exit_1_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9874049425125122     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_acc_exit_2_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9950118660926819     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_acc_exit_3_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9970071315765381     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_acc_exit_final_epoch </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9971318244934082     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_epoch_average     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0634523406624794     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06342404335737228    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_acc_exit_1_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9874049425125122    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_acc_exit_2_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9950118660926819    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_acc_exit_3_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9970071315765381    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_acc_exit_final_epoch\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9971318244934082    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_epoch_average    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0634523406624794    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06342404335737228   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.06342404335737228,\n",
       "  'test_acc_exit_1_epoch': 0.9874049425125122,\n",
       "  'test_acc_exit_2_epoch': 0.9950118660926819,\n",
       "  'test_acc_exit_3_epoch': 0.9970071315765381,\n",
       "  'test_acc_exit_final_epoch': 0.9971318244934082,\n",
       "  'test_epoch_average': 0.0634523406624794}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = EarlyExitResNet50(num_classes=3)\n",
    "\n",
    "# Set up PyTorch Lightning Trainer\n",
    "# ModelSummary(max_depth=2)\n",
    "trainer = Trainer(max_epochs=11,callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "tuner = Tuner(trainer)\n",
    "tuner.scale_batch_size(model,datamodule=data_module, mode=\"binsearch\")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define data transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# train_dataset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data', train=True, download=True, transform=transform\n",
    "# )\n",
    "# test_dataset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data', train=False, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# # Split train dataset into train and validation\n",
    "# train_size = int(0.8 * len(train_dataset))\n",
    "# val_size = len(train_dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# # Define data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EarlyExitResNet50(num_classes=3)\n",
    "# combined_state_dict = torch.load('lightning_logs/version_15/checkpoints/epoch=3-step=149660.ckpt')\n",
    "# model.load_state_dict(combined_state_dict['state_dict'])\n",
    "\n",
    "\n",
    "# profiler = AdvancedProfiler(dirpath=\".\", filename=\"perf_logs\")\n",
    "# trainer = Trainer(profiler=profiler,max_epochs=11,callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\"),ModelSummary(max_depth=2)])\n",
    "# tuner = Tuner(trainer)\n",
    "# tuner.scale_batch_size(model,datamodule=data_module, mode=\"binsearch\")\n",
    "\n",
    "\n",
    "# trainer.test(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 2            |        cudaMalloc retries: 8         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    512 B   |  21643 MiB |   2656 TiB |   2656 TiB |\n",
      "|       from large pool |      0 B   |  21590 MiB |   2654 TiB |   2654 TiB |\n",
      "|       from small pool |    512 B   |     89 MiB |      1 TiB |      1 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    512 B   |  21643 MiB |   2656 TiB |   2656 TiB |\n",
      "|       from large pool |      0 B   |  21590 MiB |   2654 TiB |   2654 TiB |\n",
      "|       from small pool |    512 B   |     89 MiB |      1 TiB |      1 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      4 B   |  21643 MiB |   2654 TiB |   2654 TiB |\n",
      "|       from large pool |      0 B   |  21590 MiB |   2653 TiB |   2653 TiB |\n",
      "|       from small pool |      4 B   |     88 MiB |      1 TiB |      1 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   6144 KiB |  22170 MiB | 178250 MiB | 178244 MiB |\n",
      "|       from large pool |      0 KiB |  22118 MiB | 177878 MiB | 177878 MiB |\n",
      "|       from small pool |   6144 KiB |     90 MiB |    372 MiB |    366 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   2047 KiB |   4632 MiB |   1194 TiB |   1194 TiB |\n",
      "|       from large pool |      0 KiB |   4630 MiB |   1193 TiB |   1193 TiB |\n",
      "|       from small pool |   2047 KiB |     29 MiB |      1 TiB |      1 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       1    |    1130    |   31720 K  |   31720 K  |\n",
      "|       from large pool |       0    |     174    |   15917 K  |   15917 K  |\n",
      "|       from small pool |       1    |    1017    |   15802 K  |   15802 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       1    |    1130    |   31720 K  |   31720 K  |\n",
      "|       from large pool |       0    |     174    |   15917 K  |   15917 K  |\n",
      "|       from small pool |       1    |    1017    |   15802 K  |   15802 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       3    |     120    |     788    |     785    |\n",
      "|       from large pool |       0    |      75    |     602    |     602    |\n",
      "|       from small pool |       3    |      45    |     186    |     183    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       2    |     217    |   17030 K  |   17030 K  |\n",
      "|       from large pool |       0    |      74    |    8196 K  |    8196 K  |\n",
      "|       from small pool |       2    |     162    |    8833 K  |    8833 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
